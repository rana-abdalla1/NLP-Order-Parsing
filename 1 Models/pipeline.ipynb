{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Splitting and Annotating Orders\n",
    "\n",
    "This notebook demonstrates how to use three models to form a pipeline for splitting the source and annotating pizza and drink orders.\n",
    "\n",
    "## Step 1: Load the Models\n",
    "\n",
    "First, we need to load the three models responsible for splitting the source, annotating pizza orders, and annotating drink orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Load the models\n",
    "splitter_model = DistilBertForSequenceClassification.from_pretrained(\"/path/to/splitter_model\")\n",
    "pizza_annotator_model = DistilBertForSequenceClassification.from_pretrained(\"/path/to/pizza_annotator_model\")\n",
    "drink_annotator_model = DistilBertForSequenceClassification.from_pretrained(\"/path/to/drink_annotator_model\")\n",
    "\n",
    "# Set the models to evaluation mode\n",
    "splitter_model.eval()\n",
    "pizza_annotator_model.eval()\n",
    "drink_annotator_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the Input Data\n",
    "\n",
    "Next, we need to preprocess the input data to prepare it for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(input_text):\n",
    "    return tokenizer(input_text, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Example input\n",
    "input_text = \"a bottle of ice tea and a dr pepper and one large diet sprite\"\n",
    "preprocessed_input = preprocess_input(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use the Splitter Model to Split the Source\n",
    "\n",
    "Use the first model to split the source into pizza and drink orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_source(preprocessed_input):\n",
    "    with torch.no_grad():\n",
    "        splitter_outputs = splitter_model(**preprocessed_input)\n",
    "        splitter_predictions = torch.argmax(splitter_outputs.logits, dim=-1)\n",
    "    \n",
    "    # Example split (this should be replaced with actual logic based on the model's output)\n",
    "    split_text = {\n",
    "        \"pizzas\": [],\n",
    "        \"drinks\": [\"a bottle of ice tea\", \"a dr pepper\", \"one large diet sprite\"]\n",
    "    }\n",
    "    return split_text\n",
    "\n",
    "split_text = split_source(preprocessed_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Use the Pizza Annotator Model to Annotate Pizza Orders\n",
    "\n",
    "Use the second model to annotate the pizza orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_pizza_orders(pizza_orders):\n",
    "    annotations = []\n",
    "    for order in pizza_orders:\n",
    "        with torch.no_grad():\n",
    "            preprocessed_order = tokenizer(order, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "            outputs = pizza_annotator_model(**preprocessed_order)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        annotations.append(predictions)\n",
    "    return annotations\n",
    "\n",
    "pizza_annotations = annotate_pizza_orders(split_text[\"pizzas\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use the Drink Annotator Model to Annotate Drink Orders\n",
    "\n",
    "Use the third model to annotate the drink orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_drink_orders(drink_orders):\n",
    "    annotations = []\n",
    "    for order in drink_orders:\n",
    "        with torch.no_grad():\n",
    "            preprocessed_order = tokenizer(order, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "            outputs = drink_annotator_model(**preprocessed_order)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        annotations.append(predictions)\n",
    "    return annotations\n",
    "\n",
    "drink_annotations = annotate_drink_orders(split_text[\"drinks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Combine and Display the Results\n",
    "\n",
    "Combine the annotations and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"pizzas\": pizza_annotations,\n",
    "    \"drinks\": drink_annotations\n",
    "}\n",
    "\n",
    "print(\"Pizza Annotations:\", results[\"pizzas\"])\n",
    "print(\"Drink Annotations:\", results[\"drinks\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
